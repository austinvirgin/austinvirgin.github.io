[
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Austin Virgin’s CV",
    "section": "",
    "text": "Computer Scientist.\n\nLinkedin\n\n\nIn school studying Computer Science\n\n\nProgramming, and data manipulation\n\n\n\nMachine Learning, and learning new programming languages\n\n\n\n\n2017 - 2021 High School, Murtaugh\n2023 - now Idaho, Brigham Young\n\n\n\n2019 CIT Fundamentals Certification\n\n\n\n2024 - now Crossroads, BYUi"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Austin Virgin’s CV",
    "section": "",
    "text": "In school studying Computer Science\n\n\nProgramming, and data manipulation\n\n\n\nMachine Learning, and learning new programming languages"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Austin Virgin’s CV",
    "section": "",
    "text": "2017 - 2021 High School, Murtaugh\n2023 - now Idaho, Brigham Young"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Austin Virgin’s CV",
    "section": "",
    "text": "2019 CIT Fundamentals Certification"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Austin Virgin’s CV",
    "section": "",
    "text": "2024 - now Crossroads, BYUi"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "notebooks/Exploration_03.html",
    "href": "notebooks/Exploration_03.html",
    "title": "Data Exploration 03",
    "section": "",
    "text": "You’re working on an exhibit for a local museum called “The Titanic Disaster”. They’ve asked you to analyze the passenger manifests and see if you can find any interesting information for the exhibit.\nThe museum curator is particularly interested in why some people might have been more likely to survive than others."
  },
  {
    "objectID": "notebooks/Exploration_03.html#part-1-import-pandas-and-load-the-data",
    "href": "notebooks/Exploration_03.html#part-1-import-pandas-and-load-the-data",
    "title": "Data Exploration 03",
    "section": "Part 1: Import Pandas and load the data",
    "text": "Part 1: Import Pandas and load the data\nRemember to import Pandas the conventional way. If you’ve forgotten how, you may want to review Data Exploration 01.\nThe dataset for this exploration is stored at the following url:\nhttps://raw.githubusercontent.com/byui-cse/cse450-course/master/data/titanic.csv\nThere are lots of ways to load data into your workspace. The easiest way in this case is to ask Pandas to do it for you.\n\nInitial Data Analysis\nOnce you’ve loaded the data, it’s a good idea to poke around a little bit to find out what you’re dealing with.\nSome questions you might ask include:\n\nWhat does the data look like?\nWhat kind of data is in each column?\nDo any of the columns have missing values?\n\n\n# Part 1: Enter your code below to import Pandas according to the\n# conventional method. Then load the dataset into a Pandas dataframe.\n\n# Write any code needed to explore the data by seeing what the first few\n# rows look like. Then display a technical summary of the data to determine\n# the data types of each column, and which columns have missing data.\nimport pandas as pd\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/titanic.csv\")\n\n\ndisplay(df.describe())\ndisplay(df.nunique())\ndisplay(df.isna().sum())\ndisplay(df.head(20))\n\n\n    \n\n\n\n\n\n\nPassengerId\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n\n\n\n\n\n\n0\n\n\n\n\nPassengerId\n891\n\n\nSurvived\n2\n\n\nPclass\n3\n\n\nName\n891\n\n\nSex\n2\n\n\nAge\n88\n\n\nSibSp\n7\n\n\nParch\n7\n\n\nTicket\n681\n\n\nFare\n248\n\n\nCabin\n147\n\n\nEmbarked\n3\n\n\n\n\ndtype: int64\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\nPassengerId\n0\n\n\nSurvived\n0\n\n\nPclass\n0\n\n\nName\n0\n\n\nSex\n0\n\n\nAge\n177\n\n\nSibSp\n0\n\n\nParch\n0\n\n\nTicket\n0\n\n\nFare\n0\n\n\nCabin\n687\n\n\nEmbarked\n2\n\n\n\n\ndtype: int64\n\n\n\n    \n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\nNo\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\nYes\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\nYes\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\nYes\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\nNo\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n5\n6\nNo\n3\nMoran, Mr. James\nmale\nNaN\n0\n0\n330877\n8.4583\nNaN\nQ\n\n\n6\n7\nNo\n1\nMcCarthy, Mr. Timothy J\nmale\n54.0\n0\n0\n17463\n51.8625\nE46\nS\n\n\n7\n8\nNo\n3\nPalsson, Master. Gosta Leonard\nmale\n2.0\n3\n1\n349909\n21.0750\nNaN\nS\n\n\n8\n9\nYes\n3\nJohnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\nfemale\n27.0\n0\n2\n347742\n11.1333\nNaN\nS\n\n\n9\n10\nYes\n2\nNasser, Mrs. Nicholas (Adele Achem)\nfemale\n14.0\n1\n0\n237736\n30.0708\nNaN\nC\n\n\n10\n11\nYes\n3\nSandstrom, Miss. Marguerite Rut\nfemale\n4.0\n1\n1\nPP 9549\n16.7000\nG6\nS\n\n\n11\n12\nYes\n1\nBonnell, Miss. Elizabeth\nfemale\n58.0\n0\n0\n113783\n26.5500\nC103\nS\n\n\n12\n13\nNo\n3\nSaundercock, Mr. William Henry\nmale\n20.0\n0\n0\nA/5. 2151\n8.0500\nNaN\nS\n\n\n13\n14\nNo\n3\nAndersson, Mr. Anders Johan\nmale\n39.0\n1\n5\n347082\n31.2750\nNaN\nS\n\n\n14\n15\nNo\n3\nVestrom, Miss. Hulda Amanda Adolfina\nfemale\n14.0\n0\n0\n350406\n7.8542\nNaN\nS\n\n\n15\n16\nYes\n2\nHewlett, Mrs. (Mary D Kingcome)\nfemale\n55.0\n0\n0\n248706\n16.0000\nNaN\nS\n\n\n16\n17\nNo\n3\nRice, Master. Eugene\nmale\n2.0\n4\n1\n382652\n29.1250\nNaN\nQ\n\n\n17\n18\nYes\n2\nWilliams, Mr. Charles Eugene\nmale\nNaN\n0\n0\n244373\n13.0000\nNaN\nS\n\n\n18\n19\nNo\n3\nVander Planke, Mrs. Julius (Emelia Maria Vande...\nfemale\n31.0\n1\n0\n345763\n18.0000\nNaN\nS\n\n\n19\n20\nYes\n3\nMasselmani, Mrs. Fatima\nfemale\nNaN\n0\n0\n2649\n7.2250\nNaN\nC"
  },
  {
    "objectID": "notebooks/Exploration_03.html#part-2-initial-exploration",
    "href": "notebooks/Exploration_03.html#part-2-initial-exploration",
    "title": "Data Exploration 03",
    "section": "Part 2: Initial Exploration",
    "text": "Part 2: Initial Exploration\nUsing your visualization library of choice, let’s first look at some features in isolation. Generate visualizations showing:\n\nA comparison of the total number of passengers who survived compared to those that died.\nA comparison of the total number of males compared to females\nA histogram showing the distribution of sibling/spouse counts\nA histogram showing the distribution of parent/child counts\n\n\n# Part 2: # Write the code needed to generate the visualizations specified.\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure()\ndisplay(sns.histplot(data = df, x = 'Survived'))\n\nplt.figure()\ndisplay(sns.histplot(data = df, x = \"Sex\"))\n\nplt.figure()\ndisplay(sns.histplot(data = df, x = 'SibSp'))\n\nplt.figure()\ndisplay(sns.histplot(data = df, x = 'Parch'))\n\n&lt;Axes: xlabel='Survived', ylabel='Count'&gt;\n\n\n&lt;Axes: xlabel='Sex', ylabel='Count'&gt;\n\n\n&lt;Axes: xlabel='SibSp', ylabel='Count'&gt;\n\n\n&lt;Axes: xlabel='Parch', ylabel='Count'&gt;"
  },
  {
    "objectID": "notebooks/Exploration_03.html#part-3-pairwise-comparisons",
    "href": "notebooks/Exploration_03.html#part-3-pairwise-comparisons",
    "title": "Data Exploration 03",
    "section": "Part 3: Pairwise Comparisons",
    "text": "Part 3: Pairwise Comparisons\nUse your visualization library of choice to look at how the survival distribution varied across different groups.\n\nChoose some features that you think might have had some influence over the likelihood of a titanic passenger surviving.\nFor each of those features, generate a chart for each feature showing the survival distributions when taking that feature into account\n\n\n# Write the code to explore how different features affect the survival distribution\ndisplay(sns.pairplot(data = df, kind = \"reg\", hue = \"Survived\", diag_kind='hist'))\nplt.figure()\ndf['age_groups'] = pd.qcut(df['Age'], q = 5)\ndisplay(sns.countplot(data = df, x = 'age_groups', hue = 'Survived'))\n\n&lt;seaborn.axisgrid.PairGrid at 0x789653f9c230&gt;\n\n\n&lt;Axes: xlabel='age_groups', ylabel='count'&gt;"
  },
  {
    "objectID": "notebooks/Exploration_03.html#part-4-feature-engineering",
    "href": "notebooks/Exploration_03.html#part-4-feature-engineering",
    "title": "Data Exploration 03",
    "section": "Part 4: Feature Engineering",
    "text": "Part 4: Feature Engineering\nThe museum curator wonders if the passenger’s rank and title might have anything to do with whether or not they survived. Since this information is embedded in their name, we’ll use “feature engineering” to create two new columns:\n\nTitle: The passenger’s title\nRank: A boolean (true/false) indicating if a passenger was someone of rank.\n\nFor the first new column, you’ll need to find a way to extract the title portion of their name. Be sure to clean up any whitespace or extra punctuation.\nFor the second new column, you’ll need to first look at a summary of your list of titles and decide what exactly constitutes a title of rank. Will you include military and eccelsiastical titles? Once you’ve made your decision, create the second column.\nYou may want to review prior Data Explorations for tips on creating new columns and checking for lists of values.\n\n# Enter the code needed to create the two new columns\ndf['Name'] = df['Name'].str.lower()\ndf['Title'] = df['Name'].str.split(',').str.get(1).str.split(\".\").str.get(0)\ndf['Rank'] = df['Title'].str.contains('master|don|rev|dr|major|col|capt|mme|lady|mlle|the countess|jonkheer')\n\n\nRevisit Visualizations\nNow that you have the new columns in place. Revisit the pairwise comparison plots to see if the new columns reveal any interesting relationships.\n\n# Enter the code needed to recheck the pairwise comparison.\nsns.countplot(data = df, x = 'Rank', hue = 'Survived')"
  },
  {
    "objectID": "notebooks/Exploration_03.html#part-5-encoding",
    "href": "notebooks/Exploration_03.html#part-5-encoding",
    "title": "Data Exploration 03",
    "section": "Part 5: Encoding",
    "text": "Part 5: Encoding\nThe museum has partnered with a data science group to build some interactive predicitive models using the titanic passenger data.\nMany machine learning algorithms require categorical features to be encoded as numbers.\nThere are two approaches to this, label encoding (sometimes called factorization), and “one-hot” encoding.\n\nLabel Encoding\nLabel encoding creates numeric labels for each categorical value. For example, imagine we have a feature in the data called Pet with these values for the first five rows: ['Dog', 'Cat', 'Dog', 'Dog', 'Bird'].\nWe could create a new feature called Pet_Encoded where those values are represented as: [0, 1, 0, 0, 2]. Where 0 = Dog, 1 = Cat, and 2 = Bird.\nIn pandas there are two common ways to label encode a feature:\n\nMethod 1: factorize()\nFirst, we could pandas’ factorize() method. It takes the series you want to encode as an argument and returns a list of two items.\nThe first item is an array of encoded values. The second is the set of original values.\n# The factorize() method returns the new values and the originals in a list.\n# So the [0] at the end indicates we want only the new values.\nmyData['Pet_Encoded'] = pd.factorize(myData['Pet'])[0]\n\n\nMethod 2: Category Data Type\nEvery column in a pandas dataframe is a certain datatype. Usually, pandas infers which datatype to use based on the values of the column. However, we can use the astype() method to convert a feature from one type to another.\nIf we first convert a feature to the category datatype, we can ask pandas to create a new column in the data frame based on the category codes:\n# Convert our column to the category type\nmyData['Pet'] = myData['Pet'].astype('category')\nmyData['Pet_Encoded'] = myData['Pet'].cat.codes\nWhichever method we choose, our machine learning algorithm could use the new Pet_Encoded feature in place of the Pet feature.\n\n# Create a new column in the dataset called \"Sex_Encoded\" containing the\n# label encoded values of the \"Sex\" column\ndf['Sex'] = df['Sex'].astype('category')\ndf['Sex_Encoded'] = df['Sex'].cat.codes\ndf\n\n\n    \n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nage_groups\nTitle\nRank\nSex_Encoded\n\n\n\n\n0\n1\nNo\n3\nbraund, mr. owen harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n(19.0, 25.0]\nmr\nFalse\n1\n\n\n1\n2\nYes\n1\ncumings, mrs. john bradley (florence briggs th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n(31.8, 41.0]\nmrs\nFalse\n0\n\n\n2\n3\nYes\n3\nheikkinen, miss. laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n(25.0, 31.8]\nmiss\nFalse\n0\n\n\n3\n4\nYes\n1\nfutrelle, mrs. jacques heath (lily may peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n(31.8, 41.0]\nmrs\nFalse\n0\n\n\n4\n5\nNo\n3\nallen, mr. william henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n(31.8, 41.0]\nmr\nFalse\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\nNo\n2\nmontvila, rev. juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n(25.0, 31.8]\nrev\nTrue\n1\n\n\n887\n888\nYes\n1\ngraham, miss. margaret edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n(0.419, 19.0]\nmiss\nFalse\n0\n\n\n888\n889\nNo\n3\njohnston, miss. catherine helen \"carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nS\nNaN\nmiss\nFalse\n0\n\n\n889\n890\nYes\n1\nbehr, mr. karl howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n(25.0, 31.8]\nmr\nFalse\n1\n\n\n890\n891\nNo\n3\ndooley, mr. patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n(31.8, 41.0]\nmr\nFalse\n1\n\n\n\n\n891 rows × 16 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\n\nOne-Hot Encoding\nOne problem with label encoding is that it can make a categorical variable appear as if it contains a quantitative relationship between its values.\nIn the example above, is Bird twice as important as Cat? Some algorithms might interpret those values that way.\nOne-Hot encoding avoids this problem by creating a new feature for each category. The value of the new feature is either 0 (is not this value) or 1 (is this value).\nIn pandas, we can use the get_dummies() method to deal with this problem:\nmyEncodedData = pd.get_dummies(myData, columns=['Pet'])\nIn the case of our Pet example, the new features created by get_dummies() would be:\n\n\n\nPet_is_Dog\nPet_is_Cat\nPet_is_Bird\n\n\n\n\n1\n0\n0\n\n\n0\n1\n0\n\n\n1\n0\n0\n\n\n1\n0\n0\n\n\n0\n0\n1\n\n\n\nNotice that for our data, if Pet_is_Bird = 0 and Pet_is_Cat = 0, we know that the pet has to be a dog. So the Pet_is_Dog column contains redundant information. When this happens, we say that our data contains a multicollinearity problem.\nTo avoid this, we can tell get_dummies() that we want to get rid of one of the columns using the drop_first parameter:\nmyEncodedData = pd.get_dummies(myData, columns=['Pet'], drop_first=True)\nThe main disadvantage to One-Hot encoding is that if the feature you’re encoding has a lot of different values, it can result in a lot of extra features. This can sometimes lead to poor performance with some types of algorithms.\n\n# Use the pandas get_dummies() method to one-hot encode the Embarked column.\nfinal = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\nfinal\n\n\n    \n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nage_groups\nTitle\nRank\nSex_Encoded\nEmbarked_Q\nEmbarked_S\n\n\n\n\n0\n1\nNo\n3\nbraund, mr. owen harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\n(19.0, 25.0]\nmr\nFalse\n1\nFalse\nTrue\n\n\n1\n2\nYes\n1\ncumings, mrs. john bradley (florence briggs th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\n(31.8, 41.0]\nmrs\nFalse\n0\nFalse\nFalse\n\n\n2\n3\nYes\n3\nheikkinen, miss. laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\n(25.0, 31.8]\nmiss\nFalse\n0\nFalse\nTrue\n\n\n3\n4\nYes\n1\nfutrelle, mrs. jacques heath (lily may peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\n(31.8, 41.0]\nmrs\nFalse\n0\nFalse\nTrue\n\n\n4\n5\nNo\n3\nallen, mr. william henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\n(31.8, 41.0]\nmr\nFalse\n1\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\nNo\n2\nmontvila, rev. juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\n(25.0, 31.8]\nrev\nTrue\n1\nFalse\nTrue\n\n\n887\n888\nYes\n1\ngraham, miss. margaret edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\n(0.419, 19.0]\nmiss\nFalse\n0\nFalse\nTrue\n\n\n888\n889\nNo\n3\njohnston, miss. catherine helen \"carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nNaN\nmiss\nFalse\n0\nFalse\nTrue\n\n\n889\n890\nYes\n1\nbehr, mr. karl howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\n(25.0, 31.8]\nmr\nFalse\n1\nFalse\nFalse\n\n\n890\n891\nNo\n3\ndooley, mr. patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\n(31.8, 41.0]\nmr\nFalse\n1\nTrue\nFalse\n\n\n\n\n891 rows × 17 columns"
  },
  {
    "objectID": "notebooks/Exploration_03.html#part-6-conclusions",
    "href": "notebooks/Exploration_03.html#part-6-conclusions",
    "title": "Data Exploration 03",
    "section": "Part 6: Conclusions",
    "text": "Part 6: Conclusions\nBased on your analysis, what interesting relationships did you find? Write three interesting facts the museum can use in their exhibit.\nI found it interesting the connection that much more not of rank survived and those who were ranking were half and half, also more females than males survived. Lastly the ages were a lot more suprisingly around the same amount."
  },
  {
    "objectID": "notebooks/Exploration_03.html#above-and-beyond",
    "href": "notebooks/Exploration_03.html#above-and-beyond",
    "title": "Data Exploration 03",
    "section": "🌟 Above and Beyond 🌟",
    "text": "🌟 Above and Beyond 🌟\n\nThere appears to be a lot of different variations of similar titles. (such as abbreviations for Miss and Mademoiselle).\nScan through the different titles to see which titles can be consolidated, then use what you know about data manipulation to simplify the distribution.\nOnce you’ve finished, check the visualizations again to see if that made any difference.\nThe museum curator has room for a couple of nice visualizations for the exhibit. Create additional visualizations that are suitable for public display.\n\n\ndf[]\n\n\n  File \"/tmp/ipython-input-1951995059.py\", line 1\n    df[]\n       ^\nSyntaxError: invalid syntax"
  },
  {
    "objectID": "notebooks/Exploration_01.html",
    "href": "notebooks/Exploration_01.html",
    "title": "Data Exploration 01",
    "section": "",
    "text": "A consumer watchdog group wants to see if Netflix has more movies for adults or children.\nUsing a dataset containing metadata for all of the movies Netflix had available on their platform in 2019, we’ll use the MPAA movie rating system to determine if they are correct."
  },
  {
    "objectID": "notebooks/Exploration_01.html#mpaa-movie-ratings",
    "href": "notebooks/Exploration_01.html#mpaa-movie-ratings",
    "title": "Data Exploration 01",
    "section": "MPAA Movie Ratings:",
    "text": "MPAA Movie Ratings:\n\nG: All ages admitted.\nPG: Some material may not be suitable for children.\nPG-13: Some material may be inappropriate for children under 13.\nR: Under 17 requires accompanying parent or adult guardian\nNC-17: No One 17 and Under Admitted\n\nMost people would consider G and PG as ratings suitable for children. However, not everyone would agree that a PG-13 movie is necssarily a children’s movie. It is up to you to decide how to handle this."
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-1-import-pandas",
    "href": "notebooks/Exploration_01.html#part-1-import-pandas",
    "title": "Data Exploration 01",
    "section": "Part 1: Import Pandas",
    "text": "Part 1: Import Pandas\nThe pandas library is a python library used for data analysis and manipulation. It will provide the core functionality for most of what you do in the data exploration and preprocessing stages of most machine learning projects.\nPlease see this Getting Started Guide for information on the conventional way to import Pandas into your project, as well as other helpful tips for common Pandas tasks.\n\n# Part 1: Enter the code below to import Pandas according to the\n# conventional method.\nimport pandas as pd"
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-2-load-the-data",
    "href": "notebooks/Exploration_01.html#part-2-load-the-data",
    "title": "Data Exploration 01",
    "section": "Part 2: Load the data",
    "text": "Part 2: Load the data\nThe dataset for this exploration is stored at the following url:\nhttps://raw.githubusercontent.com/byui-cse/cse450-course/master/data/netflix_titles.csv\nThere are lots of ways to load data into your workspace. The easiest way in this case is to ask Pandas to do it for you.\n\nInitial Data Analysis\nOnce you’ve loaded the data, it’s a good idea to poke around a little bit to find out what you’re dealing with.\nSome questions you might ask include:\n\nWhat does the data look like?\nWhat kind of data is in each column?\nDo any of the columns have missing values?\n\n\n# Part 2: Load the dataset into a Pandas dataframe.\nds = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/netflix_titles.csv\")\n\n\n# Then, explore the data by seeing what the first few rows look like.\nds.head()\n\n\n    \n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nrating\nduration\nlisted_in\ndescription\n\n\n\n\n0\n81145628\nMovie\nNorm of the North: King Sized Adventure\nRichard Finn, Tim Maltby\nAlan Marriott, Andrew Toth, Brian Dobson, Cole...\nUnited States, India, South Korea, China\nSeptember 9, 2019\n2019\nTV-PG\n90 min\nChildren & Family Movies, Comedies\nBefore planning an awesome wedding for his gra...\n\n\n1\n80117401\nMovie\nJandino: Whatever it Takes\nNaN\nJandino Asporaat\nUnited Kingdom\nSeptember 9, 2016\n2016\nTV-MA\n94 min\nStand-Up Comedy\nJandino Asporaat riffs on the challenges of ra...\n\n\n2\n70234439\nTV Show\nTransformers Prime\nNaN\nPeter Cullen, Sumalee Montano, Frank Welker, J...\nUnited States\nSeptember 8, 2018\n2013\nTV-Y7-FV\n1 Season\nKids' TV\nWith the help of three human allies, the Autob...\n\n\n3\n80058654\nTV Show\nTransformers: Robots in Disguise\nNaN\nWill Friedle, Darren Criss, Constance Zimmer, ...\nUnited States\nSeptember 8, 2018\n2016\nTV-Y7\n1 Season\nKids' TV\nWhen a prison ship crash unleashes hundreds of...\n\n\n4\n80125979\nMovie\n#realityhigh\nFernando Lebrija\nNesta Cooper, Kate Walsh, John Michael Higgins...\nUnited States\nSeptember 8, 2017\n2017\nTV-14\n99 min\nComedies\nWhen nerdy high schooler Dani finally attracts...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n# Next, display a technical summary of the data to determine the data types of each column, and which columns have missing data.\nds.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6234 entries, 0 to 6233\nData columns (total 12 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   show_id       6234 non-null   int64 \n 1   type          6234 non-null   object\n 2   title         6234 non-null   object\n 3   director      4265 non-null   object\n 4   cast          5664 non-null   object\n 5   country       5758 non-null   object\n 6   date_added    6223 non-null   object\n 7   release_year  6234 non-null   int64 \n 8   rating        6224 non-null   object\n 9   duration      6234 non-null   object\n 10  listed_in     6234 non-null   object\n 11  description   6234 non-null   object\ndtypes: int64(2), object(10)\nmemory usage: 584.6+ KB"
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-3-filter-the-data",
    "href": "notebooks/Exploration_01.html#part-3-filter-the-data",
    "title": "Data Exploration 01",
    "section": "Part 3: Filter the Data",
    "text": "Part 3: Filter the Data\nSince we’re just interested in movies, we’ll need to filter out anything that isn’t a movie for our analysis. The type feature contains this information.\nOnce we have the subset, we should see how many rows it contains. There are a variety of ways to get the length of a data frame.\n\n# Use pandas's filtering abilitites to select the subset of data\n# that represents movies, then calculate how many rows are in the filtered data.\nds = ds[ds['type'] == \"Movie\"]\n\n\nMPAA Ratings\nNow that we have only movies, let’s get a quick count of the values being used in the rating feature.\n\n# Determine the number of records for each value of the \"rating\" feature.\n# Remember to count the values in your subset only, not in the original dataframe.\nds['type'].count()\n\nnp.int64(4265)\n\n\n\n\nMore Filtering\nThere are apparently some “made for TV” movies in the list that don’t fit the MPAA rating scheme.\nLet’s filter some more to just see movies rated with the standard MPAA ratings of G, PG, PG-13, R, and NC-17.\n\n# Filter the list of movies to select a new subset containing only movies with\n# a standard MPAA rating. Calculate how many rows are in this new set, and\n# then see which ratings appear most often.\nds = ds[(ds['rating'] == 'G') | (ds['rating'] == 'PG') | (ds['rating'] == 'PG-13') | (ds['rating'] == \"R\") | (ds['rating'] == 'NC-17')]\n\n\nds['rating'].count()\n\nnp.int64(1013)\n\n\n\nds['rating'].mode()\n\n\n\n\n\n\n\n\nrating\n\n\n\n\n0\nR\n\n\n\n\ndtype: object"
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-4-visualization",
    "href": "notebooks/Exploration_01.html#part-4-visualization",
    "title": "Data Exploration 01",
    "section": "Part 4: Visualization",
    "text": "Part 4: Visualization\nNow that we have explored and preprocessed our data, let’s create a visualization to summarize our findings.\n\nExploration vs Presentation\nBroadly speaking, there are two types of visualizations: * Barebones visualizations you might use to get a quick, visual understanding of the data while you’re trying to decide how it all fits together. * Presentation-quality visualizations that you would include in a report or presentation for management or other stakeholders.\n\n\nVisualization Tools\nThere are many different visualization tools availble. In the sections below, we’ll explore the three most common. Each of these libraries has strengths and weaknesses.\nIt is probably a good idea for you to become familiar with each one, and then become proficient at whichever one you like the best.\n\n\nAltair\nThe Altair visualization library provides a large variety of very easy to use statistical charting tools.\nAltair uses a declarative language to build up charts piece by piece.\nAssume we have a pandas dataframe called employees, with three columns: name, job, salary.\n# Make a box plot style categorical plot showing the distribution of salaries for each job:\nalt.Chart(employees).mark_boxplot().encode(\n    x='job',\n    y='salary'\n)\n\n# Make a box plot style categorical plot, and customize the results\nalt.Chart(employees).mark_boxplot().encode(\n    alt.X('job', title='Job title'),\n    alt.Y('salary', title='Annual salary in thousands of $USD')\n).properties(\n  title='Salaries by Job Title'\n)\nLike with Pandas, there is a conventional way to import Altair into your projects.\n\n# Import the Altair library the conventional way.\nimport altair as alt\n\nLet’s create a barchart showing the count of each movie rating by using Altair’s aggregation capabilities.\nIn this example, we see the x axis being set to a feature called a, and the y axis set to the average() of a feature called b.\nIn our case, we want the x axis to be set to rating and the y axis to be the count() of rating.\n\n# Use Altair to create a bar chart comparing the count of each movie rating\nalt.Chart(ds).mark_bar().encode(\n    x='rating',\n    y='count(rating)'\n)\n\n\n\n\n\n\n\n\n\nSeaborn\nWhile Altair uses a “declarative” syntax for building charts piece by piece, the Seaborn library provides a large variety of pre-made charts for common statistical needs.\nThese charts are divided into different categories. Each category has a high-level interface you can use for simplicity, and then a specific function for each chart that you can use if you need more control over how the chart looks.\nSeaborn uses matplotlib for its drawing, and the chart-specific functions each return a matplitlib axes object if you need additional customization.\nFor example, there are several different types of categorical plots in seaborn: bar plots, box plots, point plots, count plots, swarm plots, etc…\nEach of these plots can be accessed using the catplot function.\nAssume we have a pandas dataframe called employees, with three columns: name, job, salary.\n# Make a box plot style categorical plot showing the distribution of salaries for each job:\nsns.catplot(data=employees, x='job', y='salary', kind='box')\n\n# Make a swarm plot style categorical plot\nsns.catplot(data=employees, x='job', y='salary', kind='swarm')\nAlternatively, you can use the plot specific functions to give yourself more control over the output by using matplotlib functions:\n# Make a box plot style categorical plot, and customize the results\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 9))\nax = sns.boxplot(data=employees, x='job', y='salary')\nax.set_title(\"Salaries by Job Title\")\nax.set_ylabel(\"Annual salary in thousands of $USD\")\nax.set_xlabel(\"Job title\")\nLike with Pandas, there is a conventional way to import Seaborn into your projects.\nOptionally, you may wish to set some default chart aesthetics by setting the chart style.\n\n# Import the seaborn library the conventional way. Then optionally configure\n# the default chart style.\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nSince the rating column uses categorical data, we need to use Seaborn’s categorical visualizations.\nIn particular, we want a “count plot” that will display a count of movie ratings.\n\n# Use seaborn to create a count plot comparing the count of each movie rating\nsns.catplot(data = ds, x = 'rating', kind = 'count')\n\n\n\n\n\n\n\n\n\n\nPandas built-in plotting\nIn addition to libraries like Altair and Seaborn, Pandas has some built in charting functionality.\nWhile not as sophisticated as some of the other options, it is often good enough for quick visualizations.\nJust like with seaborn’s plotting functions, the pandas plotting functions return matplotlib axes objects, which can be further customized.\nAssume we have a pandas dataframe called employees, with three columns: name, job, salary.\n# Make a box plot style categorical plot showing the distribution of salaries for each job:\nemployees[ ['job','salary'] ].plot.box()\n\n# Make a box plot style categorical plot, and customize the results\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 9))\nax = employees[ ['job','salary'] ].plot().box()\nax.set_title(\"Salaries by Job Title\")\nax.set_ylabel(\"Annual salary in thousands of $USD\")\nax.set_xlabel(\"Job title\")\n\n# Use pandas' built in plotting functions to create a count plot comparing the count of each movie rating\n# This will be a little trickier than the other libraries, but one hint is that the pandas value_counts() function\n# actually returns a dataframe.\nds['rating'].value_counts().plot.bar()"
  },
  {
    "objectID": "notebooks/Exploration_01.html#above-and-beyond",
    "href": "notebooks/Exploration_01.html#above-and-beyond",
    "title": "Data Exploration 01",
    "section": "🌟 Above and Beyond 🌟",
    "text": "🌟 Above and Beyond 🌟\nAfter reviewing your findings, the watchdog group would like some additional questions answered:\n\nHow are things affected if you include the “made for TV movies” that have been assigned TV ratings in your analysis, but still exclude unrated movies?\nThey would also like to see a separate report that includes only TV shows.\nFor an upcoming community meeting, the group would like to present a simple chart showing “For Kids” and “For Adults” categories. The easiest way to accomplish this would be to create a new column in your data frame that maps each rating to the appropriate “For Kids” or “For Adults” label, then create a new visualization based on that column.\n\n\nds['age_group'] = ds['rating'].replace({'G' : 'For Kids', 'PG': 'For Kids', 'PG-13': \"For Adults\", \"R\": \"For Adults\", 'NC-17': \"For Adults\"})\nds['age_group'].value_counts().plot.bar()"
  },
  {
    "objectID": "notebooks/Exploration_02.html",
    "href": "notebooks/Exploration_02.html",
    "title": "Data Exploration 02",
    "section": "",
    "text": "You’re working as a data analyst at a cereal marketing company in New York.\nIn a strategy meeting, the marketing director tells you that in 2018, the US weight loss industry was worth over $72 Billion dollars, growing 4% compared to the previous year.\nIn contrast, sales of cold cereal fell 6% to $8.5 billion during the same time period.\nCereal executives have approached the marketing company asking how they can somehow tap into the weight loss market growth to boost the sales of their cereal brands.\nYour assignment is to analyze a dataset of nutritional information for major US cereals, and calculate some metrics that can be used by the marketing team."
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-1-import-pandas-and-load-the-data",
    "href": "notebooks/Exploration_02.html#part-1-import-pandas-and-load-the-data",
    "title": "Data Exploration 02",
    "section": "Part 1: Import Pandas and load the data",
    "text": "Part 1: Import Pandas and load the data\nRemember to import Pandas the conventional way. If you’ve forgotten how, you may want to review Data Exploration 01.\nThe dataset for this exploration is stored at the following url:\nhttps://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv\nThere are lots of ways to load data into your workspace. The easiest way in this case is to ask Pandas to do it for you.\n\nInitial Data Analysis\nOnce you’ve loaded the data, it’s a good idea to poke around a little bit to find out what you’re dealing with.\nSome questions you might ask include:\n\nWhat does the data look like?\nWhat kind of data is in each column?\nDo any of the columns have missing values?\n\n\n# Part 1: Enter your code below to import Pandas according to the\n# conventional method. Then load the dataset into a Pandas dataframe.\n\n# Write any code needed to explore the data by seeing what the first few\n# rows look like. Then display a technical summary of the data to determine\n# the data types of each column, and which columns have missing data.\n\nimport pandas as pd\n\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv\")\n\ndf.head()\n\n\n    \n\n\n\n\n\n\nname\nmfr\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n0\n100% Bran\nN\nC\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.0\n0.33\n68.402973\n\n\n1\n100% Natural Bran\nQ\nC\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.0\n1.00\n33.983679\n\n\n2\nAll-Bran\nK\nC\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.0\n0.33\n59.425505\n\n\n3\nAll-Bran with Extra Fiber\nK\nC\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.0\n0.50\n93.704912\n\n\n4\nAlmond Delight\nR\nC\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.0\n0.75\n34.384843\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 77 entries, 0 to 76\nData columns (total 16 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   name      77 non-null     object \n 1   mfr       77 non-null     object \n 2   type      77 non-null     object \n 3   calories  77 non-null     int64  \n 4   protein   77 non-null     int64  \n 5   fat       77 non-null     int64  \n 6   sodium    77 non-null     int64  \n 7   fiber     77 non-null     float64\n 8   carbo     77 non-null     float64\n 9   sugars    77 non-null     int64  \n 10  potass    77 non-null     int64  \n 11  vitamins  77 non-null     int64  \n 12  shelf     77 non-null     int64  \n 13  weight    77 non-null     float64\n 14  cups      77 non-null     float64\n 15  rating    77 non-null     float64\ndtypes: float64(5), int64(8), object(3)\nmemory usage: 9.8+ KB"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-2-calculate-summary-statistics",
    "href": "notebooks/Exploration_02.html#part-2-calculate-summary-statistics",
    "title": "Data Exploration 02",
    "section": "Part 2: Calculate Summary Statistics",
    "text": "Part 2: Calculate Summary Statistics\nThe marketing team has determined that when choosing a cereal, consumers are most interested in calories, sugars, fiber, fat, and protein.\nFirst, let’s calcuate some summary statistics for these categories across the entire dataset. We’re particularly intrested in the mean, median, standard deviation, min, and max values.\nThere are multiple ways to accomplish this.\n\n# Part 2: Enter your code below to calculate summary statistics for the\n# calories, sugars, fiber, fat, and protein features.\nsummary = df[[\"calories\", \"sugars\", \"fiber\", \"fat\", \"protein\"]]\n\nsummary.describe()\n\n\n    \n\n\n\n\n\n\ncalories\nsugars\nfiber\nfat\nprotein\n\n\n\n\ncount\n77.000000\n77.000000\n77.000000\n77.000000\n77.000000\n\n\nmean\n106.883117\n6.922078\n2.151948\n1.012987\n2.545455\n\n\nstd\n19.484119\n4.444885\n2.383364\n1.006473\n1.094790\n\n\nmin\n50.000000\n-1.000000\n0.000000\n0.000000\n1.000000\n\n\n25%\n100.000000\n3.000000\n1.000000\n0.000000\n2.000000\n\n\n50%\n110.000000\n7.000000\n2.000000\n1.000000\n3.000000\n\n\n75%\n110.000000\n11.000000\n3.000000\n2.000000\n3.000000\n\n\nmax\n160.000000\n15.000000\n14.000000\n5.000000\n6.000000"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-3-transform-data",
    "href": "notebooks/Exploration_02.html#part-3-transform-data",
    "title": "Data Exploration 02",
    "section": "Part 3: Transform Data",
    "text": "Part 3: Transform Data\nTo make analysis easier, you want to convert the manufacturer codes used in the dataset to the manufacturer names.\nFirst, display the count of each manufacturer code value used in the dataset (found in the mfr column).\nThen, create a new column with the appropriate manufacturer name for each entry, using this mapping:\nA = American Home Food Products\nG = General Mills\nK = Kelloggs\nN = Nabisco\nP = Post\nQ = Quaker Oats\nR = Ralston Purina\n\nNote: While the tutorial linked above uses the replace function, using the map function instead can often be much faster and more memory efficient, especially for large datasets.\n\n\n# Display the count of values for the manufacturer code (\"mfr\" column), then\n# create a new column containing the appropriate manufacturer names.\n\ndf['manufacturer'] = df['mfr'].map({'A' : \"American Home Food Products\", \"G\" : \"General Mills\", \"K\" : \"Kellogs\", \"N\": \"Nabisco\", \"P\" : \"Post\", \"Q\" : \"Quaker Oats\", \"R\" : \"Ralston Purina\"})\ndf\n\n\n    \n\n\n\n\n\n\nname\nmfr\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\nmanufacturer\n\n\n\n\n0\n100% Bran\nN\nC\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.0\n0.33\n68.402973\nNabisco\n\n\n1\n100% Natural Bran\nQ\nC\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.0\n1.00\n33.983679\nQuaker Oats\n\n\n2\nAll-Bran\nK\nC\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.0\n0.33\n59.425505\nKellogs\n\n\n3\nAll-Bran with Extra Fiber\nK\nC\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.0\n0.50\n93.704912\nKellogs\n\n\n4\nAlmond Delight\nR\nC\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.0\n0.75\n34.384843\nRalston Purina\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n72\nTriples\nG\nC\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.0\n0.75\n39.106174\nGeneral Mills\n\n\n73\nTrix\nG\nC\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.0\n1.00\n27.753301\nGeneral Mills\n\n\n74\nWheat Chex\nR\nC\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.0\n0.67\n49.787445\nRalston Purina\n\n\n75\nWheaties\nG\nC\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.0\n1.00\n51.592193\nGeneral Mills\n\n\n76\nWheaties Honey Gold\nG\nC\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.0\n0.75\n36.187559\nGeneral Mills\n\n\n\n\n77 rows × 17 columns"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-4-visualization",
    "href": "notebooks/Exploration_02.html#part-4-visualization",
    "title": "Data Exploration 02",
    "section": "Part 4: Visualization",
    "text": "Part 4: Visualization\nLet’s do some more data exploration visually.\nImport your visualization library of choice and set any needed configuration options.\n\n# Import your visualization library\nimport seaborn as sns\n\n\nSugar Distribution\nMarketing tells us that their surveys have revealed that sugar content is the number one concern of consumers when choosing cereal.\nThey would like to see the following visualizations:\n\nA histogram plot of the sugar content in all cereals.\nA scatter plot showing the relationship between sugar and calories.\nA box plot showing the distribution of sugar content by manufacturer.\n\n\n# Create the three visualzations requested by the the marketing team\nsns.displot(data = df, x = \"sugars\")\n\n\n\n\n\n\n\n\n\nsns.scatterplot(data = df, x = 'sugars', y = 'calories')\n\n\n\n\n\n\n\n\n\nsns.boxplot(data = df, x = 'manufacturer', y = 'sugars')"
  },
  {
    "objectID": "notebooks/Exploration_02.html#above-and-beyond",
    "href": "notebooks/Exploration_02.html#above-and-beyond",
    "title": "Data Exploration 02",
    "section": "🌟 Above and Beyond 🌟",
    "text": "🌟 Above and Beyond 🌟\nThe marketing team is pleased with what you’ve accomplished so far. They have a meeting with top cereal executives in the morning, and they’d like you to do as many of the following additional tasks as you have time for:\n\nWeight Watchers used to have an older points system that used this formula: (calories / 50) + (fat / 12) - (fiber / 5), but only the first 4 grams of fiber were included in the calculation. For comparison’s sake, create an additional column with the calculation for the old points system.\nMarketing really likes the boxplot of the sugar content for each cereal, they’d like similar plots for calories and fat, but using different color schemes for each chart.\n\n\ndf['fibers_total'] = df['fiber'].where(df['fiber'] &lt;= 4, other = 4)\ndf['ww_old'] = (df['calories'] / 50) + (df['fat'] / 12) - (df['fiber'] / 5)\ndf = df.drop(columns = ['fibers_total'])\ndf\n\n\n    \n\n\n\n\n\n\nname\nmfr\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\nmanufacturer\nww\nww_old\n\n\n\n\n0\n100% Bran\nN\nC\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.0\n0.33\n68.402973\nNabisco\n2.738\n-0.516667\n\n\n1\n100% Natural Bran\nQ\nC\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.0\n1.00\n33.983679\nQuaker Oats\n5.701\n2.416667\n\n\n2\nAll-Bran\nK\nC\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.0\n0.33\n59.425505\nKellogs\n2.618\n-0.316667\n\n\n3\nAll-Bran with Extra Fiber\nK\nC\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.0\n0.50\n93.704912\nKellogs\n1.133\n-1.800000\n\n\n4\nAlmond Delight\nR\nC\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.0\n0.75\n34.384843\nRalston Purina\n4.669\n2.166667\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n72\nTriples\nG\nC\n110\n2\n1\n250\n0.0\n21.0\n3\n60\n25\n3\n1.0\n0.75\n39.106174\nGeneral Mills\n3.794\n2.283333\n\n\n73\nTrix\nG\nC\n110\n1\n1\n140\n0.0\n13.0\n12\n25\n25\n2\n1.0\n1.00\n27.753301\nGeneral Mills\n4.972\n2.283333\n\n\n74\nWheat Chex\nR\nC\n100\n3\n1\n230\n3.0\n17.0\n3\n115\n25\n1\n1.0\n0.67\n49.787445\nRalston Purina\n3.391\n1.483333\n\n\n75\nWheaties\nG\nC\n100\n3\n1\n200\n3.0\n17.0\n3\n110\n25\n1\n1.0\n1.00\n51.592193\nGeneral Mills\n3.391\n1.483333\n\n\n76\nWheaties Honey Gold\nG\nC\n110\n2\n1\n200\n1.0\n16.0\n8\n60\n25\n1\n1.0\n0.75\n36.187559\nGeneral Mills\n4.394\n2.083333\n\n\n\n\n77 rows × 19 columns"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  }
]